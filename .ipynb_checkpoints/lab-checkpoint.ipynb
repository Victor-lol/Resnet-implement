{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c31cd433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import RandomSampler,SequentialSampler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3a93a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"data/test.csv\"\n",
    "train_path = \"data/train.csv\"\n",
    "image_path = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f10d8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8bbc238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['label'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ca71e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeaveDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 csv_path, \n",
    "                 img_file,\n",
    "                 mode=\"train\", valid_ratio=.2):\n",
    "\n",
    "        self.mode = mode\n",
    "        self.root = img_file\n",
    "        \n",
    "        csv_data = pd.read_csv(csv_path, header=None)\n",
    "        n_example = len(csv_data) - 1\n",
    "        self.train_len = int(n_example * (1 - valid_ratio))\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            self.train_img_path = np.asarray(csv_data.iloc[1:self.train_len,0])\n",
    "            self.train_label = np.asarray(csv_data.iloc[1:self.train_len, 1].unique())\n",
    "            n_class = len(self.train_label)\n",
    "            self.num_to_label = dict(zip(self.train_label, range(n_class)))\n",
    "            self.label_to_num = {v: k for k, v in self.num_to_label.items()}\n",
    "            \n",
    "        elif mode == \"valid\":\n",
    "            self.valid_img_path = np.asarray(csv_data.iloc[self.train_len:,0])\n",
    "            self.valid_label = np.asarray(csv_data.iloc[self.train_len:,1].unique())\n",
    "            n_class = len(self.valid_label)\n",
    "            self.num_to_label = dict(zip(self.valid_label, range(n_class)))\n",
    "            self.label_to_num = {v: k for k, v in self.num_to_label.items()}\n",
    "            \n",
    "        else:\n",
    "            self.test_img_path = np.asarray(csv_data.iloc[1:,0])\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            img_path = self.train_img_path[index]\n",
    "            img = Image.open(self.root + img_path)\n",
    "            \n",
    "            transform = transforms.Compose([\n",
    "                \n",
    "                transforms.Resize(224),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "            label = self.label_to_num[index]\n",
    "            return transform(img), label \n",
    "        else:\n",
    "            if self.mode == \"valid\":\n",
    "                img_path = self.valid_img_path[index]\n",
    "                img = Image.open(self.root + img_path)\n",
    "                transform = transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])\n",
    "                label = self.label_to_num[idnex]\n",
    "                return transform(img), label\n",
    "            else:\n",
    "                img_path = self.test_img_path[index]\n",
    "                img = Image.open(self.root + img_path)\n",
    "                return img\n",
    "       \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            return len(self.train_label)\n",
    "        elif self.mode == \"valid\":\n",
    "            return len(self.valid_label)\n",
    "        else:\n",
    "            return len(self.test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "18e6209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LeaveDataset(\n",
    "    csv_path=train_path, \n",
    "    img_file=image_path,\n",
    "    mode=\"train\"\n",
    ")\n",
    "valid_dataset =  LeaveDataset(\n",
    "    csv_path=train_path, \n",
    "    img_file=image_path,\n",
    "    mode=\"valid\"\n",
    ")\n",
    "test_dataset =  LeaveDataset(\n",
    "    csv_path=test_path, \n",
    "    img_file=image_path,\n",
    "    mode=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "525368a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset, batch_size, n_workers, sampler):\n",
    "    return  DataLoader(\n",
    "        dataset=dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=n_workers, \n",
    "        sampler=sampler\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "61559173",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_data(train_dataset, 32, 0, RandomSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4f5edbea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/images/10.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-545cee4ea7df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-117-5a2febcbd88c>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_img_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             transform = transforms.Compose([\n",
      "\u001b[1;32m~\\.conda\\envs\\DeepLearning\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2967\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2968\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2969\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/images/10.jpg'"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for batch in train_loader:\n",
    "        img, label = batch\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f03f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel, kernel=3, padding=1,use_1conv=False,strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channel,\n",
    "            out_channels=out_channel, \n",
    "            kernel_size=kernel, \n",
    "            padding=padding, \n",
    "            stride=strides)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channel,\n",
    "            out_channels=out_channel,\n",
    "            kernel_size=kernel, \n",
    "            padding=padding)\n",
    "    \n",
    "        if use_1conv:\n",
    "            self.conv3 = nn.Conv2d(\n",
    "                in_channels=in_channel, \n",
    "                out_channels=out_channel, \n",
    "                kernel_size=1,\n",
    "                stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.conv3:\n",
    "            x = self.conv3(x)\n",
    "        out += x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f10b7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(in_channels, out_channels, n_residuals, kernel=3, padding=1, first_block=False):\n",
    "    blocks = []\n",
    "    for i in range(n_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blocks.append(Residual(in_channels, out_channels,\n",
    "                                use_1conv=True, strides=2))\n",
    "        else:\n",
    "            blocks.append(Residual(out_channels, out_channels))\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12849a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_labels):\n",
    "        super().__init__()\n",
    "        self.n_labels = n_labels\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(*resnet_block(64,64,2,first_block=True))\n",
    "        self.block3 = nn.Sequential(*resnet_block(64,128,2))\n",
    "        self.block4 = nn.Sequential(*resnet_block(128,256,2))\n",
    "        self.block5 = nn.Sequential(*resnet_block(256,512,2))\n",
    "        self.avgPool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.ffn = nn.Linear(512, n_labels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.avgPool(x)\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.ffn(x)\n",
    "        x = F.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ad59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, \n",
    "          data_loader, \n",
    "          optimizer, \n",
    "          n_epochs, \n",
    "          loss_fn, \n",
    "          device, \n",
    "          batch_size):\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        with torch.enable_grad(), tqdm(total=len(data_loader.dataset)) as pbar:\n",
    "            for batch in data_loader:\n",
    "                optimizer.grad_zero()\n",
    "                img, label = batch\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                pred = model(img)\n",
    "                loss = loss_fn(pred, label)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                pbar.update(batch_size)\n",
    "                pbar.set_postfix(epoch=epoch, loss=loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "547d9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet18()\n",
    "X = torch.rand(size=(1, 1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90120e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victor\\.conda\\envs\\DeepLearning\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "out = resnet(X)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e049f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2115, 0.9462, 0.5771,  ..., 0.2715, 0.8972, 0.8427],\n",
       "          [0.3082, 0.7258, 0.6873,  ..., 0.4697, 0.9020, 0.4433],\n",
       "          [0.8736, 0.2819, 0.2084,  ..., 0.8368, 0.7171, 0.7920],\n",
       "          ...,\n",
       "          [0.9148, 0.1651, 0.0162,  ..., 0.2623, 0.4546, 0.4492],\n",
       "          [0.1979, 0.0238, 0.6904,  ..., 0.9718, 0.2023, 0.0023],\n",
       "          [0.5575, 0.2381, 0.4994,  ..., 0.7385, 0.9487, 0.4454]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "350f6bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6, 6])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = ResidualBlock(3,3,3,1)\n",
    "X = torch.rand(4, 3, 6, 6)\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e76ae74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3, 3])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = ResidualBlock(3,6,3,1,use_1conv=True, strides=2)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1c453c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(in_channels, out_channels, n_residuals, kernel=3, padding=1, first_block=False):\n",
    "    blocks = []\n",
    "    for i in range(n_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blocks.append(ResidualBlock(input_channels, out_channels,\n",
    "                                use_1conv=True, strides=2))\n",
    "        else:\n",
    "            blocks.append(ResidualBlock(out_channels, out_channels))\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a1772acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78034d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
